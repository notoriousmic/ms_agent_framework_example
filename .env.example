# Azure OpenAI Configuration
AZURE_OPENAI_API_KEY=""
AZURE_OPENAI_ENDPOINT=""
AZURE_OPENAI_API_VERSION="2025-03-01-preview"
AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME=""

# Observability & Tracing Configuration
# Enable OpenTelemetry tracing for all LLM calls
ENABLE_OTEL=true

# Include sensitive data (prompts/responses) in traces - use false in production
ENABLE_SENSITIVE_DATA=false

# Optional: OTLP endpoint for custom telemetry collector
# OTLP_ENDPOINT=http://localhost:4317

# Azure Application Insights connection string for Azure AI Foundry tracing
# Get this from Azure Portal -> Application Insights -> Properties
# APPLICATIONINSIGHTS_CONNECTION_STRING="InstrumentationKey=your-key;IngestionEndpoint=https://your-region.in.applicationinsights.azure.com/"

# Brave Search API Configuration (required for Research Agent)
# Get your API key from https://brave.com/search/api/
BRAVE_API_KEY=""

# Azure AI Foundry Project Configuration (REQUIRED for agent visibility in portal)
# Get these from Azure AI Foundry portal -> Project Settings
# The AZURE_AI_PROJECT_ENDPOINT is required for agents to appear in Azure AI Foundry portal
# Example: AZURE_AI_PROJECT_ENDPOINT="https://your-resource.services.ai.azure.com/api/projects/your-project"
# Authentication: Make sure to run 'az login' before starting the application
AZURE_SUBSCRIPTION_ID=""
RESOURCE_GROUP_NAME=""
PROJECT_NAME=""
AZURE_AI_PROJECT_ENDPOINT=""
AZURE_AI_MODEL_DEPLOYMENT_NAME=""  # Usually same as AZURE_OPENAI_RESPONSES_DEPLOYMENT_NAME
